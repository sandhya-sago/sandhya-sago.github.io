<!DOCTYPE html>
<meta charset="utf-8">
<head>
<style>

body {
  font: 10px sans-serif;
}

.group-tick line {
  stroke: #000;
}

.ribbons {
  fill-opacity: 0.67;
}
.group path {
fill-opacity: .5;
}
 
path.chord {
stroke: #000;
stroke-width: .25px;
}
 
#circle:hover path.fade {
display: none;
}
.fade {
display: none;
}

</style>
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

</head>
<body>
  <div class="container-fluid">
  <p>Google BigQuery has a few open datasets, of which GitHub data is one. However, one can get only 16k rows in a 
    query without paying extra for storage. So, I got a list of 16k most watched repositories from sample_repos (which 
    is a list of 400k repositories which got more than 2 starts during Jan-May 2016). GitHub data is available at 
    <a href="https://bigquery.cloud.google.com/dataset/bigquery-public-data:github_repos">Google Big Query</a>.
  </p>
  <p class="text-monospace">
    <pre>
SELECT
    sample_repos.repo_name,
    sample_repos.watch_count,
    languages.LANGUAGE
FROM
  `bigquery-public-data.github_repos.languages` languages
INNER JOIN
  `bigquery-public-data.github_repos.sample_repos` sample_repos
ON
  languages.repo_name = sample_repos.repo_name
WHERE sample_repos.repo_name IN (
  SELECT repo_name[OFFSET(0)]
  FROM `bigquery-public-data.github_repos.commits`)
ORDER BY sample_repos.watch_count DESC
LIMIT 16000
    </pre>
  </p>

<svg width="960" height="960"></svg>
<script src="https://d3js.org/d3.v4.min.js"></script>
<script src="data.js"></script>
<script src="logic.js"></script>
</div>
</body>
</html>
